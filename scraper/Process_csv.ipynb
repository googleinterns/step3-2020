{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Process_csv.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QjSIYLFPUok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-Jns0OYPYfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "\n",
        "def read_files(files):\n",
        "  df = pd.concat(map(pd.read_csv, files))\n",
        "  return df\n",
        "\n",
        "def process_link(link):\n",
        "  # remove orgs with malformed url\n",
        "  if link.find('.') == -1:\n",
        "    return ''\n",
        "  # exclude facebook/guidestar/wikipedia links\n",
        "  if 'facebook' in link or 'guidestar' in link or 'wikipedia' in link:\n",
        "    return ''\n",
        "  index = link.find('â€º')\n",
        "  if index > -1:\n",
        "    link = link[: index - 1]\n",
        "  return link\n",
        "\n",
        "# Name: only first letter is capitalized\n",
        "# Link: remove Facebook/guidestar\n",
        "# Remove special characters to keep only valid URLs\n",
        "# About: Change to sentence case\n",
        "def process_text(df):\n",
        "  output = []\n",
        "  for _, org in df.iterrows(): \n",
        "    name = org['name'].title()\n",
        "    link = org['link']\n",
        "    about_input = org['about']\n",
        "    # remove orgs without url or about\n",
        "    if type(link) == str and type(about_input) == str:\n",
        "      url = process_link(str(link))\n",
        "    else:\n",
        "      continue\n",
        "    if not url:\n",
        "      continue\n",
        "    # about = re.sub(r'\\d+', '', about_input.capitalize())\n",
        "    about = about_input.capitalize()\n",
        "    output.append([name, url, about])\n",
        "  return output\n",
        "\n",
        "def save_results(results, start, stop):\n",
        "  with open('/content/drive/My Drive/Capstone/processed_data/medium/processed_irs990_' + str(start) + '_' + str(stop) + '.csv', 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['name', 'link', 'about'])\n",
        "    for data in results:\n",
        "      writer.writerow(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTL8rHh8P7D6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start = 5000\n",
        "stop = 10000\n",
        "step = 50\n",
        "files = ['/content/drive/My Drive/Capstone/scraped_data/links_irs990_' + str(i)\n",
        "    + '_' + str(i + step) + '.csv' for i in range(start, stop, step)]\n",
        "df = read_files(files)\n",
        "processed = process_text(df)\n",
        "save_results(processed, start, stop)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}